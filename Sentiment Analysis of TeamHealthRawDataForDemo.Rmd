---
title: "Sentiment Analysis Using R Programming"
author: "Stephen Fabeyo"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```




```{r, echo=FALSE, include=FALSE}

# Installing and loading R packages
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
library("syuzhet")
library("ggplot2")

```

---------

# Text Mining and Sentiment Analysis: Analysis with R

---------

### Reading file data into R

---------


```{r}

text <- readLines('TeamHealthRawDataForDemo.txt')

# Load the data as a corpus
TextDoc <- Corpus(VectorSource(text))

TextDoc
```

---------

### Cleaning up Text Data

---------

```{r, warning=FALSE}

#Replacing "/", "@" and "|" with space

toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
TextDoc <- tm_map(TextDoc, toSpace, "/")
TextDoc <- tm_map(TextDoc, toSpace, "@")
TextDoc <- tm_map(TextDoc, toSpace, "\\|")


# Convert the text to lower case

TextDoc <- tm_map(TextDoc, content_transformer(tolower))

# Remove numbers

TextDoc <- tm_map(TextDoc, removeNumbers)

# Remove english common stopwords

TextDoc <- tm_map(TextDoc, removeWords, stopwords("english"))

# Remove your own stop word
# specify your custom stopwords as a character vector

TextDoc <- tm_map(TextDoc, removeWords, c("s", "company", "team")) 

# Remove punctuations

TextDoc <- tm_map(TextDoc, removePunctuation)

# Eliminate extra white spaces

TextDoc <- tm_map(TextDoc, stripWhitespace)

# Text stemming - which reduces words to their root form

TextDoc <- tm_map(TextDoc, stemDocument)


TextDoc
```

---------

### Building the term document matrix

---------

```{r}

# Build a term-document matrix

TextDoc_dtm <- TermDocumentMatrix(TextDoc)

dtm_m <- as.matrix(TextDoc_dtm)

# Sort by descearing value of frequency

dtm_v <- sort(rowSums(dtm_m),decreasing=TRUE)

dtm_d <- data.frame(word = names(dtm_v),freq=dtm_v)

# Display the top 5 most frequent words

head(dtm_d, 5)

```

---------

### Plot the most frequent words

---------

```{r}

barplot(dtm_d[1:5,]$freq, las = 2, names.arg = dtm_d[1:5,]$word,
        col ="lightgreen", main ="Top 5 most frequent words",
        ylab = "Word frequencies")

```

---------

### Generate the Word Cloud

---------

```{r}

set.seed(1234)
wordcloud(words = dtm_d$word, freq = dtm_d$freq, min.freq = 5,
          max.words=100, random.order=FALSE, rot.per=0.40, 
          colors=brewer.pal(8, "Dark2"))

```

---------

### Word Association

---------


```{r}

# Find associations 

findAssocs(TextDoc_dtm, terms = c("good","work","health"), corlimit = 0.25)			

```


```{r}
# Find associations for words that occur at least 50 times

findAssocs(TextDoc_dtm, terms = findFreqTerms(TextDoc_dtm, lowfreq = 50), corlimit = 0.25)


```


---------

### Sentiment Scores

---------


```{r}

# regular sentiment score using get_sentiment() function and method of your choice
# please note that different methods may have different scales

syuzhet_vector <- get_sentiment(text, method="syuzhet")

# see the first row of the vector

head(syuzhet_vector)

# see summary statistics of the vector

summary(syuzhet_vector)

```


---------

### Syuzhet vector

---------

```{r}

# bing

bing_vector <- get_sentiment(text, method="bing")
head(bing_vector)
summary(bing_vector)

#affin

afinn_vector <- get_sentiment(text, method="afinn")
head(afinn_vector)
summary(afinn_vector)

```

---------

### Emotion Classification

---------

```{r}


# run nrc sentiment analysis to return data frame with each row classified as one of the following
# emotions, rather than a score: 
# anger, anticipation, disgust, fear, joy, sadness, surprise, trust 
# It also counts the number of positive and negative emotions found in each row

d<-get_nrc_sentiment(text)

# head(d,10) - to see top 10 lines of the get_nrc_sentiment dataframe

head (d,10)

```

---------

### Bar Plot showing the count of words in the text, associated with each emotion.

---------

```{r}

#transpose

td<-data.frame(t(d))

#The function rowSums computes column sums across rows for each level of a grouping variable.

td_new <- data.frame(rowSums(td[2:253]))

#Transformation and cleaning

names(td_new)[1] <- "count"
td_new <- cbind("sentiment" = rownames(td_new), td_new)
rownames(td_new) <- NULL
td_new2<-td_new[1:8,]

#Plot One - count of words associated with each sentiment

quickplot(sentiment, data=td_new2, weight=count, geom="bar", fill=sentiment, ylab="count")+ggtitle("Survey sentiments")


```


---------

### Bar Plot showing the count of words associated with each sentiment expressed as a percentage

---------

```{r}


#Plot two - count of words associated with each sentiment, expressed as a percentage

barplot(
  sort(colSums(prop.table(d[, 1:8]))), 
  horiz = TRUE, 
  cex.names = 0.7, 
  las = 1, 
  main = "Emotions in Text", xlab="Percentage"
)

```


