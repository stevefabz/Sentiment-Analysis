---
title: "Deciphering Email Content Using Sentiment Analysis"
author: "Group 2: Stephen Fabeyo, Sebastian Castaldi, Malcom Eades"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

---------

This project leverages sentiment analysis to delve into the content of emails, focusing on understanding the emotional and sentimental nuances rather than filtering spam. By analyzing the sentiments expressed in emails, the project aims to provide insights that could improve email management and security, ensuring a more context-aware approach to handling digital communication.

---------


```{r, echo=FALSE, include=FALSE}

library(tm)  # For text mining
library(SnowballC)  # For text processing
library(wordcloud)  # For creating word clouds
library(RColorBrewer)  # For color palettes
library(syuzhet)  # For sentiment analysis
library(ggplot2)  # For plotting
library(caret)  # For machine learning
library(e1071)  # For SVM model, used by caret for classification
library(kernlab) # For kernel-based machine learning methods in R

```

---------

# Text Mining and Sentiment Analysis: email/spam Analysis

---------

Step 1: Reading file data into R

---------


```{r}

data <- read.csv('spam.csv', stringsAsFactors = FALSE)

```

--------

Summary Statistics

-------


```{r}

print(summary(data))

```

---------

Step 2: Text Preprocessing.

---------

```{r, warning=FALSE}


TextCorpus <- Corpus(VectorSource(data$Message))

# Function to replace "/", "@" and "|" with space
toSpace <- content_transformer(function (x, pattern) gsub(pattern, " ", x))

# Apply the transformations
TextCorpus <- tm_map(TextCorpus, toSpace, "/")
TextCorpus <- tm_map(TextCorpus, toSpace, "@")
TextCorpus <- tm_map(TextCorpus, toSpace, "\\|")
TextCorpus <- tm_map(TextCorpus, content_transformer(tolower))
TextCorpus <- tm_map(TextCorpus, removeNumbers)
TextCorpus <- tm_map(TextCorpus, removeWords, stopwords("english"))
TextCorpus <- tm_map(TextCorpus, removeWords, c("s", "company", "team"))
TextCorpus <- tm_map(TextCorpus, removePunctuation)
TextCorpus <- tm_map(TextCorpus, stripWhitespace)
TextCorpus <- tm_map(TextCorpus, stemDocument)

TextCorpus

```

---------

Step 3:  Visualize Important Terms

---------

```{r, warning=FALSE}

dtm <- TermDocumentMatrix(TextCorpus)
dtm_matrix <- as.matrix(dtm)

dtm_v <- sort(rowSums(dtm_matrix),decreasing=TRUE)

dtm_d <- data.frame(word = names(dtm_v),freq=dtm_v)

# Display the top 5 most frequent words

head(dtm_d, 10)

```

---------

Sentiment Scores in Email

---------

```{r}

barplot(dtm_d[1:10,]$freq, las = 2, names.arg = dtm_d[1:10,]$word,
        col ="lightgreen", main ="Sentiment Scores in Emails",
        ylab = "Word frequencies")

```

---------

The most frequent words

---------

```{r}

set.seed(1234)
wordcloud(words = dtm_d$word, freq = dtm_d$freq, min.freq = 5,
          max.words=100, random.order=FALSE, rot.per=0.40, 
          colors=brewer.pal(8, "Dark2"))
```

---------

Step 3: Sentiment Analysis.

---------

```{r, warning=FALSE, include=FALSE}

sentiment<- sapply(sapply(TextCorpus, as.character), get_nrc_sentiment)

sentiment

```


---------

Sentiment scores

---------

```{r, warning=FALSE}

# Initialize a numeric vector to store sentiment scores

sentiment_scores <- numeric(length(data$Message))

```


Loop through each message and calculate sentiment score

```{r, warning=FALSE}


for (i in 1:length(data$Message)) {
  # Directly store the sentiment score; no need to access a 'valence' component
  sentiment_scores[i] <- get_sentiment(data$Message[i], method = "nrc")
}


```


Assign sentiment scores to the data frame

```{r, warning=FALSE}

data$Sentiment <- sentiment_scores

data

```


---------

Emotion Classification

---------

```{r}


emotion<- get_nrc_sentiment(data$Message)

# head(d,10) - to see top 10 lines of the get_nrc_sentiment dataframe

head (emotion,5)

```

---------

Survey Sentiments

---------

```{r}

#transpose

td<-data.frame(t(emotion))

#The function rowSums computes column sums across rows for each level of a grouping variable.

td_new <- data.frame(rowSums(td[2:253]))

#Transformation and cleaning

names(td_new)[1] <- "count"
td_new <- cbind("sentiment" = rownames(td_new), td_new)
rownames(td_new) <- NULL
td_new2<-td_new[1:8,]

#Plot One - count of words associated with each sentiment

quickplot(sentiment, data=td_new2, weight=count, geom="bar", fill=sentiment, ylab="count")+ggtitle("Survey sentiments")


```


---------

Bar Plot showing the count of words associated with each sentiment expressed as a percentage

---------

```{r}


#Plot two - count of words associated with each sentiment, expressed as a percentage

barplot(
  sort(colSums(prop.table(emotion[, 1:8]))), 
  horiz = TRUE, 
  cex.names = 0.7, 
  las = 1, 
  main = "Emotions in Text", xlab="Percentage"
)

```



